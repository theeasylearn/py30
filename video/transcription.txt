in the last couple of lectures we understood the concept of event driven architecture in node JS now in this lecture let's talk about another important concept in node JS which is streams so let's understand streams and let's understand what is the advantages provides let's forget a simple example to understand what is not a stream let's say we want to read a file for that we are going to use this read file method and we want to read the source file.txt now when we use read file method to read a file in between a buffer is created from the source file the content is red in the read buffer and all the content is red at once and then that red content is available in our node JS application so here we are storing that content in the data variable now we want to write the data the content which we have in the data variable in another file that we need to use this right file method right we have already seen this so here we want to write the data the content which we have in this data variable to let's say a destination file and to do that when we use write file method it creates a right buffer in between and then it rights all the data in that buffer and from that buffer the data is written to the destination file and again all these happens at once the right file method write all the data in the buffer at once and then that data is written in the destination file so this is how the normal read and write words when we read a file using read file method when the read file completes reading all the content from the specified file that data will be stored in the memory and then it will be available for use if the file is very large it is still going to read all the data from the file before it makes it available for use and it might take some time in reading all the content from that file the file is very large once all the content from that large file is read then only that content will be available for use that content will be stored in the systems memory and it will be available for use the problem here is that since we are reading a large file and once that large file is completely red we are going to store all that data in the systems memory so it is going to take a lot of memory to store that data now which stream we can process that is we can read and write data piece by piece instead of reading or writing the whole data at once therefore we don't have to keep all the data in the memory to do these operations for example let's say we want to read a file and this time we are going to make use of going to read the content of the source file to do that again read buffer will be created where the content will be written first you can think of this read buffer as the memory in your system the content which we are reading from the source file that will be stored but since we are using stream here in between the source file and delete buffer there will be a stream which will get created and using this stream instead of reading all the content at once we can read the contents peace by peace junk by chunks and in this way we are not storing all the data in the memory we are reading a chunk we are storing it in the memory and we are using it and then we have seen the memory storing it in the memory we are using it and then the memory and this process is repeated until the entire file has been processed and this is what stream is think of YouTube on Netflix which are both called as streaming companies because the stream videos using the same principle so here instead of waiting until the entire video file loads the processing is done please by peace and also say so that you can start watching videos even before the entire file has been downloaded and this principle does not apply only to node JS but it is common in Computer Science in general and this makes stream the perfect candidate for handling large volume of data for example streaming live videos live matches or when creating a streaming app and also for the data that we are receiving piece by piece from an external source so the advantage of using streaming is that streaming makes the data processing more efficient in terms of memory because there is no need to keep all the data in the memory in terms of performance and time also streaming has it advantage because we can start processing the data as soon as the first check of data types of a bit about how they are implemented in node JS so in node JS there are four types of streams readable streams right table streams duplex streams and transform streams here the readable and readable streams are the most important and common ones and so we are going to focus more on these two we will also talk about duplex string and transform stream on a high level and understand what we use it for the readable streams are the one from where we can read or consume data for example when we send a request to the node server the request data which we received on the server will receive it through readablestream so when we send a request to the server a readable stream is open and through that readable stream we get the request data in chunks that means the request data which comes on the server it comes in peace by peace and not the complete data at once another example of readablestream would be from the file system we can read a file by using the create read stream from the FS module which can actually be quite useful for reading last text files another important dreams are actually instances of event M class that means all types of streams can EMIT and listen to name events and we will understand this practically in our next lecture in case of readable streams we can EMIT and we can listen to many events but the most important to events of readablestream are the data and the end event the data event is limited when there is a new piece or new chunk of data to consume for example when we are reading a file using readstream the data will be reading chance so whenever a new chunk of data is red and available to use the data event will be emitted and the independent is emitted as soon as there is no more data to consume for example let's say we are reading data check by junk from a file once all the chunk of data is received and there is no more chunk of data available the end event will be raised and of course when this event happens we can react to these events accordingly we will understand we important functions that we can use on a stream and in case of readable stream the most important functions are the pipe and read functions in simple words the read function can be called when we want to read each junk from the readablestream one after the other and the pipe function allows us to plug strange together passing data from one string to another without having to worry much about the events at all for example we can read data from a readable stream and we can write it to the right table string simultaneously using the pipe method we will learn more about pipe method in our next lecture now let's talk about truth table streams are the ones to which we can write data it is basically the opposite of readablestream a great example of right table string will be the http response that we can send back to the client and which is actually a right tables team that is the stream that we can write data into so basically when you want to send data we want to write it somewhere right and that's something that somewhere is the right table stream for example if you want to send a big video file to the client we would stream the result just like Netflix or YouTube do instead of sending the complete video file at once the two important events of right table stream are the drain and finish event the drain event is released when the right table streams internal buffer has been updated and the finish event in a right table stream is emitted after calling of the end method when all the data is being flushed to the hidden system basically it's similar to independent readablestream the most important functions which we have on right table stream is the right hand in function and will understand it practically in our next lecture so these are the two main stream variable stream now let's talk about stream that is both readable and readable at the same time this team is combination of readable and readable stream which type of streams are a bit less common and a good example of duplex stream would be the websocket from the net module a web socket is basically a communication channel between client and the server which works in both the direction and it is open once the connection has been established a simple example websockets are used in the real time chat apps from streams are the duplex streams that is the streams that are both readable and readable and at the same time it can modify a transform the data as it is red or written a good example of this one is the lead to compress data which actually uses it transform these are the four types of streams and abroad overview of how we can use them we can also implement our own streams and then consume them and I will cover how to do that in one of the lectures of this course but for the most part of the application development with node J we don't need to worry about implementing our own streams the readable and readable stream should be enough so this is all from this lecture in the next lecture let's understand streams with practically examples